{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd28eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e4f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29T16:44:27.000Z</td>\n",
       "      <td>Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Might just sack everything off and go and live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29T15:36:51.000Z</td>\n",
       "      <td>Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>3 rd island Aachu arjun sir should have questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-29T14:50:23.000Z</td>\n",
       "      <td>BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Reply with your favourite BALI Awards memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-29T14:26:04.000Z</td>\n",
       "      <td>No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...</td>\n",
       "      <td>But are Japanese free to pop over to Hawaii fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29T14:24:28.000Z</td>\n",
       "      <td>Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...</td>\n",
       "      <td>#MythologyMonday\\nThis myth explains the origi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0  2021-11-29T16:44:27.000Z   \n",
       "1  2021-11-29T15:36:51.000Z   \n",
       "2  2021-11-29T14:50:23.000Z   \n",
       "3  2021-11-29T14:26:04.000Z   \n",
       "4  2021-11-29T14:24:28.000Z   \n",
       "\n",
       "                                            Username  \\\n",
       "0                 Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021   \n",
       "1                  Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021   \n",
       "2        BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021   \n",
       "3  No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...   \n",
       "4  Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...   \n",
       "\n",
       "                                               Tweet  \n",
       "0  Might just sack everything off and go and live...  \n",
       "1  3 rd island Aachu arjun sir should have questi...  \n",
       "2  Reply with your favourite BALI Awards memories...  \n",
       "3  But are Japanese free to pop over to Hawaii fo...  \n",
       "4  #MythologyMonday\\nThis myth explains the origi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dirty-en.csv', encoding = 'latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886201cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26762 entries, 0 to 26761\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Date      26762 non-null  object\n",
      " 1   Username  26762 non-null  object\n",
      " 2   Tweet     26762 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 627.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7410bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c151fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20131 entries, 0 to 26761\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Date      20131 non-null  object\n",
      " 1   Username  20131 non-null  object\n",
      " 2   Tweet     20131 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 629.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29T16:44:27.000Z</td>\n",
       "      <td>Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Might just sack everything off and go and live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29T15:36:51.000Z</td>\n",
       "      <td>Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>3 rd island Aachu arjun sir should have questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-29T14:50:23.000Z</td>\n",
       "      <td>BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Reply with your favourite BALI Awards memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-29T14:26:04.000Z</td>\n",
       "      <td>No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...</td>\n",
       "      <td>But are Japanese free to pop over to Hawaii fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29T14:24:28.000Z</td>\n",
       "      <td>Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...</td>\n",
       "      <td>#MythologyMonday\\nThis myth explains the origi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0  2021-11-29T16:44:27.000Z   \n",
       "1  2021-11-29T15:36:51.000Z   \n",
       "2  2021-11-29T14:50:23.000Z   \n",
       "3  2021-11-29T14:26:04.000Z   \n",
       "4  2021-11-29T14:24:28.000Z   \n",
       "\n",
       "                                            Username  \\\n",
       "0                 Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021   \n",
       "1                  Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021   \n",
       "2        BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021   \n",
       "3  No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...   \n",
       "4  Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...   \n",
       "\n",
       "                                               Tweet  \n",
       "0  Might just sack everything off and go and live...  \n",
       "1  3 rd island Aachu arjun sir should have questi...  \n",
       "2  Reply with your favourite BALI Awards memories...  \n",
       "3  But are Japanese free to pop over to Hawaii fo...  \n",
       "4  #MythologyMonday\\nThis myth explains the origi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5572eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d70eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text(tweet):\n",
    "    tokenized_text = tweet.split()\n",
    "    return tokenized_text\n",
    "df['tokens'] = df['cleaned_tweet'].apply(lambda x: tokenized_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1d6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleansing(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.replace(',', '')\n",
    "    tweet = re.sub('(www\\.[^s]+ | (https?://[^\\s]+))', 'URL', tweet)\n",
    "    tweet = re.sub('[^\\w]', ' ', tweet)\n",
    "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)\n",
    "    tweet = re.sub('#([^\\s]+)', '\\1', tweet)\n",
    "    tweet = re.sub('[^a-zA-Z#]', ' ', tweet)\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935c165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = df.Tweet.apply(tweet_cleansing).values\n",
    "df['cleaned_tweet'] = df.cleaned_tweet.apply(lambda x: ' '.join([j for j in x.split() if len(j)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313710a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_words'] = df.cleaned_tweet.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fefbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>len_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29T16:44:27.000Z</td>\n",
       "      <td>Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Might just sack everything off and go and live...</td>\n",
       "      <td>might just sack everything live beach bali som...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29T15:36:51.000Z</td>\n",
       "      <td>Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>3 rd island Aachu arjun sir should have questi...</td>\n",
       "      <td>island aachu arjun should have questioned viji...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-29T14:50:23.000Z</td>\n",
       "      <td>BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Reply with your favourite BALI Awards memories...</td>\n",
       "      <td>reply with your favourite bali awards memories...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-29T14:26:04.000Z</td>\n",
       "      <td>No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...</td>\n",
       "      <td>But are Japanese free to pop over to Hawaii fo...</td>\n",
       "      <td>japanese free over hawaii trip bali</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29T14:24:28.000Z</td>\n",
       "      <td>Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...</td>\n",
       "      <td>#MythologyMonday\\nThis myth explains the origi...</td>\n",
       "      <td>mythologymonday this myth explains origins rac...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0  2021-11-29T16:44:27.000Z   \n",
       "1  2021-11-29T15:36:51.000Z   \n",
       "2  2021-11-29T14:50:23.000Z   \n",
       "3  2021-11-29T14:26:04.000Z   \n",
       "4  2021-11-29T14:24:28.000Z   \n",
       "\n",
       "                                            Username  \\\n",
       "0                 Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021   \n",
       "1                  Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021   \n",
       "2        BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021   \n",
       "3  No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...   \n",
       "4  Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  Might just sack everything off and go and live...   \n",
       "1  3 rd island Aachu arjun sir should have questi...   \n",
       "2  Reply with your favourite BALI Awards memories...   \n",
       "3  But are Japanese free to pop over to Hawaii fo...   \n",
       "4  #MythologyMonday\\nThis myth explains the origi...   \n",
       "\n",
       "                                       cleaned_tweet  len_words  \n",
       "0  might just sack everything live beach bali som...         52  \n",
       "1  island aachu arjun should have questioned viji...        206  \n",
       "2  reply with your favourite bali awards memories...         73  \n",
       "3                japanese free over hawaii trip bali         35  \n",
       "4  mythologymonday this myth explains origins rac...        223  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a3da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2abbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stopword = set(stopwords.words('english'))\n",
    "lemmatized = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7efcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizerku(tweet):\n",
    "    words = word_tokenize(tweet)\n",
    "    tokens = []\n",
    "    for i in words:\n",
    "        pattern = re.compile(r'(.)\\1{1,}', re.DOTALL)\n",
    "        i = pattern.sub(r'\\1\\1', i)\n",
    "        i = i.strip('\\'\"?,.')\n",
    "        alp = re.search(r'^[a-zA-Z0-9][a-zA-Z0-9-]*$', i)\n",
    "        if(i in ['AT_USER', 'URL'] or alp is None):\n",
    "            continue\n",
    "        else:\n",
    "            i = lemmatized.lemmatize(i)\n",
    "            tokens.append(i.lower())\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bea6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = df.cleaned_tweet.apply(lambda x: ' '.join([s for s in x.split() if s not in stopword]))\n",
    "df['cleaned_tweet'] = df.cleaned_tweet.apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa1f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>len_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29T16:44:27.000Z</td>\n",
       "      <td>Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Might just sack everything off and go and live...</td>\n",
       "      <td>might sack everything live beach bali someth</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29T15:36:51.000Z</td>\n",
       "      <td>Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>3 rd island Aachu arjun sir should have questi...</td>\n",
       "      <td>island aachu arjun questioned viji gave left r...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-29T14:50:23.000Z</td>\n",
       "      <td>BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021</td>\n",
       "      <td>Reply with your favourite BALI Awards memories...</td>\n",
       "      <td>reply favourite bali awards memories take trip...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-29T14:26:04.000Z</td>\n",
       "      <td>No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...</td>\n",
       "      <td>But are Japanese free to pop over to Hawaii fo...</td>\n",
       "      <td>japanese free hawaii trip bali</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29T14:24:28.000Z</td>\n",
       "      <td>Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...</td>\n",
       "      <td>#MythologyMonday\\nThis myth explains the origi...</td>\n",
       "      <td>mythologymonday myth explains origins races ku...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0  2021-11-29T16:44:27.000Z   \n",
       "1  2021-11-29T15:36:51.000Z   \n",
       "2  2021-11-29T14:50:23.000Z   \n",
       "3  2021-11-29T14:26:04.000Z   \n",
       "4  2021-11-29T14:24:28.000Z   \n",
       "\n",
       "                                            Username  \\\n",
       "0                 Jack\\n@_JackRFC_\\nÂ·\\nNov 29, 2021   \n",
       "1                  Muki\\n@Mukila19\\nÂ·\\nNov 29, 2021   \n",
       "2        BALI Awards\\n@BALI_Awards\\nÂ·\\nNov 29, 2021   \n",
       "3  No Base! æ²ç¸ Okinawa\\n@nobaseyellow\\nÂ·\\nNo...   \n",
       "4  Mythological Africans\\n@MythicAfricans\\nÂ·\\nNo...   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  Might just sack everything off and go and live...   \n",
       "1  3 rd island Aachu arjun sir should have questi...   \n",
       "2  Reply with your favourite BALI Awards memories...   \n",
       "3  But are Japanese free to pop over to Hawaii fo...   \n",
       "4  #MythologyMonday\\nThis myth explains the origi...   \n",
       "\n",
       "                                       cleaned_tweet  len_words  \n",
       "0       might sack everything live beach bali someth         52  \n",
       "1  island aachu arjun questioned viji gave left r...        206  \n",
       "2  reply favourite bali awards memories take trip...         73  \n",
       "3                     japanese free hawaii trip bali         35  \n",
       "4  mythologymonday myth explains origins races ku...        223  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7365c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.to_csv('en-cleaned-tweet-1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
