{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0872b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28acffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('id-labeled-tweet-1.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed1da3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>len_words</th>\n",
       "      <th>tokens</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>label_sentiment</th>\n",
       "      <th>label_willingness</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>willingness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29 23:52:01+00:00</td>\n",
       "      <td>snoop\\n@peppreoni\\nÃÂÃÂ·\\nNov 30, 2021</td>\n",
       "      <td>Temenku weekend kemarin ada yg ke Bali sama ke...</td>\n",
       "      <td>temenku weekend kemarin bal sama jogja jadi pe...</td>\n",
       "      <td>74</td>\n",
       "      <td>['temenku', 'weekend', 'kemarin', 'bal', 'sama...</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>positif</td>\n",
       "      <td>not_visit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-29 22:31:38+00:00</td>\n",
       "      <td>ÃÂ¡ÃÂ¬ÃÂ³ÃÂ¡ÃÂ¬ÃÂÃÂ¡ÃÂ¬ÃÂ¸ÃÂ¡ÃÂ¬Ã...</td>\n",
       "      <td>btw saya thn 1999 udah pernah punya pacar dari...</td>\n",
       "      <td>1999 pernah punya pacar chat kirim2 foto lewat...</td>\n",
       "      <td>126</td>\n",
       "      <td>['1999', 'pernah', 'punya', 'pacar', 'chat', '...</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>netral</td>\n",
       "      <td>visit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-29 21:37:51+00:00</td>\n",
       "      <td>Rito \"A FOOD\"\\n@FoodRito\\nÃÂÃÂ·\\nNov 30, 2021</td>\n",
       "      <td>Ya klo bgtu jangan paksa Bali jadi wisata halal</td>\n",
       "      <td>jangan paksa bal jadi wisata halal</td>\n",
       "      <td>40</td>\n",
       "      <td>['jangan', 'paksa', 'bal', 'jadi', 'wisata', '...</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>negatif</td>\n",
       "      <td>not_visit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-29 17:23:02+00:00</td>\n",
       "      <td>miamiawwwwwww\\n@poesee77\\nÃÂÃÂ·\\nNov 30, 2021</td>\n",
       "      <td>Jadi rencanannya awal desember ini gue dan beb...</td>\n",
       "      <td>jadi rencanannya awal desember beberapa teman ...</td>\n",
       "      <td>85</td>\n",
       "      <td>['jadi', 'rencanannya', 'awal', 'desember', 'b...</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>positif</td>\n",
       "      <td>visit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29 15:34:54+00:00</td>\n",
       "      <td>Handydanielk\\n@Night_prince08\\nÃÂÃÂ·\\nNov 2...</td>\n",
       "      <td>Orang bali kalo mau flexing liburan pda kmna y ?</td>\n",
       "      <td>orang bal kalau flexing libur kmna</td>\n",
       "      <td>36</td>\n",
       "      <td>['orang', 'bal', 'kalau', 'flexing', 'libur', ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>netral</td>\n",
       "      <td>not_visit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2021-11-29 23:52:01+00:00   \n",
       "1  2021-11-29 22:31:38+00:00   \n",
       "2  2021-11-29 21:37:51+00:00   \n",
       "3  2021-11-29 17:23:02+00:00   \n",
       "4  2021-11-29 15:34:54+00:00   \n",
       "\n",
       "                                            Username  \\\n",
       "0          snoop\\n@peppreoni\\nÃÂÃÂ·\\nNov 30, 2021   \n",
       "1  ÃÂ¡ÃÂ¬ÃÂ³ÃÂ¡ÃÂ¬ÃÂÃÂ¡ÃÂ¬ÃÂ¸ÃÂ¡ÃÂ¬Ã...   \n",
       "2   Rito \"A FOOD\"\\n@FoodRito\\nÃÂÃÂ·\\nNov 30, 2021   \n",
       "3   miamiawwwwwww\\n@poesee77\\nÃÂÃÂ·\\nNov 30, 2021   \n",
       "4  Handydanielk\\n@Night_prince08\\nÃÂÃÂ·\\nNov 2...   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  Temenku weekend kemarin ada yg ke Bali sama ke...   \n",
       "1  btw saya thn 1999 udah pernah punya pacar dari...   \n",
       "2    Ya klo bgtu jangan paksa Bali jadi wisata halal   \n",
       "3  Jadi rencanannya awal desember ini gue dan beb...   \n",
       "4   Orang bali kalo mau flexing liburan pda kmna y ?   \n",
       "\n",
       "                                       cleaned_tweet  len_words  \\\n",
       "0  temenku weekend kemarin bal sama jogja jadi pe...         74   \n",
       "1  1999 pernah punya pacar chat kirim2 foto lewat...        126   \n",
       "2                 jangan paksa bal jadi wisata halal         40   \n",
       "3  jadi rencanannya awal desember beberapa teman ...         85   \n",
       "4                 orang bal kalau flexing libur kmna         36   \n",
       "\n",
       "                                              tokens  year  month  \\\n",
       "0  ['temenku', 'weekend', 'kemarin', 'bal', 'sama...  2021     11   \n",
       "1  ['1999', 'pernah', 'punya', 'pacar', 'chat', '...  2021     11   \n",
       "2  ['jangan', 'paksa', 'bal', 'jadi', 'wisata', '...  2021     11   \n",
       "3  ['jadi', 'rencanannya', 'awal', 'desember', 'b...  2021     11   \n",
       "4  ['orang', 'bal', 'kalau', 'flexing', 'libur', ...  2021     11   \n",
       "\n",
       "  label_sentiment label_willingness  sentiment_score  willingness_score  \n",
       "0         positif         not_visit              NaN                NaN  \n",
       "1          netral             visit              NaN                NaN  \n",
       "2         negatif         not_visit              NaN                NaN  \n",
       "3         positif             visit              NaN                NaN  \n",
       "4          netral         not_visit              NaN                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abaad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'label_sentiment', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bab28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "\n",
    "for i in df['cleaned_tweet'][df['sentiment_score']==1].values:\n",
    "    for w in i.split():\n",
    "        cnt[w]+=1\n",
    "most_common = cnt.most_common(200)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_word = set(f for (f, fw) in most_common)\n",
    "#freq_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac451b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_freq(x):\n",
    "#    return ' '.join([word for word in str(x).split() if word not in freq_word])\n",
    "#df['common_tweet'] = df.cleaned_tweet.apply(lambda x: remove_freq(x))\n",
    "\n",
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19ff5a",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1880956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import PIL.Image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca4950",
   "metadata": {},
   "source": [
    "## Persepsi Positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_positif = np.array(PIL.Image.open('twitter.jpg'))\n",
    "color = ImageColorGenerator(mask_positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de29550",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_positif = ' '.join([p for p in df['cleaned_tweet'][df['sentiment_score']==1]])\n",
    "cloud_positif = WordCloud(max_font_size = 300, \n",
    "                          margin = 0, \n",
    "                          background_color = 'white', \n",
    "                          mask = mask_positif,\n",
    "                          min_font_size = 3,\n",
    "                          stopwords = ['bali', 'trip', 'travel', 'indonesia', 'tourist', 'people', 'thailand', 'tour', 'island', 'beach']).generate(word_positif)\n",
    "cloud_p = cloud_positif.recolor(color_func = color)\n",
    "plt.figure(figsize = [25, 25])\n",
    "plt.imshow(cloud_positif, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.margins(x = 0, y = 0)\n",
    "plt.title('Persepsi Positif', size = 35)\n",
    "plt.show()\n",
    "\n",
    "cloud_p.to_file('id-WC Sentiment Positif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93234beb",
   "metadata": {},
   "source": [
    "## Persepsi Netral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_netral = np.array(PIL.Image.open('cloud.jpg'))\n",
    "color = ImageColorGenerator(mask_netral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923b296",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_netral = ' '.join([p for p in df['cleaned_tweet'][df['sentiment_score']==0]])\n",
    "cloud_netral = WordCloud(max_font_size = 75, \n",
    "                         margin = 0, \n",
    "                         background_color = 'white', \n",
    "                         mask = mask_netral,\n",
    "                         min_font_size = 3,\n",
    "                         stopwords = ['bali', 'trip', 'travel', 'indonesia', 'tourist', 'people', 'thailand', 'tour', 'island', 'beach']).generate(word_netral)\n",
    "cloud_nt = cloud_netral.recolor(color_func = color)\n",
    "plt.figure(figsize = [25, 25])\n",
    "plt.imshow(cloud_netral, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.margins(x = 0, y = 0)\n",
    "plt.title('Persepsi Netral', size = 35)\n",
    "plt.show()\n",
    "\n",
    "cloud_nt.to_file('id-WC Sentiment Netral.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5556b3e",
   "metadata": {},
   "source": [
    "## Persepsi Negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f415d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_negatif = np.array(PIL.Image.open('sun.jpg'))\n",
    "color = ImageColorGenerator(mask_negatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_negatif = ' '.join([p for p in df['cleaned_tweet'][df['sentiment_score']==-1]])\n",
    "cloud_negatif = WordCloud(max_font_size = 300, \n",
    "                          margin = 0, \n",
    "                          background_color = 'white', \n",
    "                          mask = mask_negatif,\n",
    "                          min_font_size = 3,\n",
    "                          stopwords = ['bali', 'trip', 'travel', 'indonesia', 'tourist', 'people', 'thailand', 'tour', 'island', 'beach']).generate(word_negatif)\n",
    "cloud_ng = cloud_negatif.recolor(color_func = color)\n",
    "plt.figure(figsize = [25, 25])\n",
    "plt.imshow(cloud_negatif, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.margins(x = 0, y = 0)\n",
    "plt.title('Persepsi Negatif', size = 35)\n",
    "plt.show()\n",
    "\n",
    "cloud_ng.to_file('id-WC Sentiment Negatif.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ca2cd",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830668b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_df = 0.5, min_df = 2)\n",
    "tfidf = tfidf_vect.fit_transform(df.cleaned_tweet)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfcb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf\n",
    "y = df[['label_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c292f06",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b668d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import randint\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9546a69",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "\n",
    "#hyperparameter_svm = { 'C' : randint(low = 0.1, high = 1000),\n",
    "#                      'gamma' : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#                      'kernel' : ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "#                      'random_state' : randint(low = 0, high = 100)\n",
    "#                     }\n",
    "#svm = SVC()\n",
    "#svm_random = RandomizedSearchCV(svm, param_distributions = hyperparameter_svm,\n",
    "#                               n_iter = 10, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "#svm_random.fit(x_train, y_train)\n",
    "#svm_random.best_params_\n",
    "#svm_random.best_score_\n",
    "#svm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07707337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "hyperparameter_svm = { 'C' : [0.1, 1, 10, 100, 1000],\n",
    "                      'gamma' : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                      'kernel' : ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "                     }\n",
    "svm = SVC(random_state = 0)\n",
    "svm_random = RandomizedSearchCV(svm, param_distributions = hyperparameter_svm,\n",
    "                               n_iter = 100, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "svm_random.fit(x_train, y_train)\n",
    "#svm_random.best_params_\n",
    "#svm_random.best_score_\n",
    "#svm_random.best_estimator_\n",
    "\n",
    "pprint(svm_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e845b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameter_svm = { 'C' : [14],\n",
    "                      'gamma' : [0.1],\n",
    "                      'kernel' : ['sigmoid'],\n",
    "                      'random_state' : [0]\n",
    "                     }\n",
    "svm = SVC()\n",
    "svm_random = RandomizedSearchCV(svm, param_distributions = hyperparameter_svm,\n",
    "                               n_iter = 100, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "svm_random.fit(x_train, y_train)\n",
    "#svm_random.best_estimator_\n",
    "svm_predict = svm_random.predict(x_test)\n",
    "print(classification_report(y_test, svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5547d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM uses randint\n",
    "\n",
    "#hyperparameter_svm = { 'C' : [705],\n",
    "#                      'gamma' : [1],\n",
    "#                      'kernel' : ['sigmoid'],\n",
    "#                      'random_state' : [37]\n",
    "#                     }\n",
    "#svm = SVC(random_state = 0)\n",
    "#svm_random = RandomizedSearchCV(svm, param_distributions = hyperparameter_svm,\n",
    "#                               n_iter = 10, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "#svm_random.fit(x_train, y_train)\n",
    "#svm_random.best_estimator_\n",
    "#svm_predict = svm_random.predict(x_test)\n",
    "#print(classification_report(y_test, svm_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e9996",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hyperparameter_rf = {'n_estimators' : [1, 50, 100, 150, 300, 500, 1000],\n",
    "                     'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "                     'max_depth' : [1, 3, 5, 7, 8, 9, 10],\n",
    "                     'min_samples_split' : [1, 2, 3, 5, 7, 8, 9, 10],\n",
    "                     'min_samples_leaf' : [1, 2, 3, 5, 7, 8, 9, 10],\n",
    "                    }\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(rf, param_distributions = hyperparameter_rf,\n",
    "                              n_iter = 100, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "rf_random.fit(x_train, y_train)\n",
    "#svm_random.best_params_\n",
    "#svm_random.best_score_\n",
    "#rf_random.best_estimator_\n",
    "\n",
    "pprint(rf_random.best_estimator_.get_params())\n",
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3186dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameter_rf = {'n_estimators' : [1],\n",
    "                     'max_depth' : [7],\n",
    "                     'criterion' : ['gini'],\n",
    "                     'min_samples_split' : [8],\n",
    "                     'min_samples_leaf' : [1]\n",
    "                    }\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(rf, param_distributions = hyperparameter_rf,\n",
    "                              n_iter = 100, cv = 5, scoring = 'accuracy', random_state = 0)\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_predict = rf_random.predict(x_test)\n",
    "print(classification_report(y_test, rf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b6829",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "hyperparameter_dtc = {'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "                      'max_depth' : [1, 3, 5, 7, 8, 9, 10],\n",
    "                      'min_samples_split' : [1, 2, 3, 5, 7, 8, 9, 10],\n",
    "                      'min_samples_leaf' : [1, 2, 3, 5, 7, 8, 9, 10]\n",
    "                     }\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_random = RandomizedSearchCV(dtc, param_distributions = hyperparameter_dtc,\n",
    "                               n_iter = 100, cv =5, scoring = 'accuracy', random_state = 0)\n",
    "dtc_random.fit(x_train, y_train)\n",
    "pprint(dtc_random.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "hyperparameter_dtc = {'criterion' : ['gini'],\n",
    "                      'max_depth' : [7],\n",
    "                      'min_samples_split' : [9],\n",
    "                      'min_samples_leaf' : [1]\n",
    "                     }\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_random = RandomizedSearchCV(dtc, param_distributions = hyperparameter_dtc,\n",
    "                               n_iter = 100, cv =5, scoring = 'accuracy', random_state = 0)\n",
    "dtc_random.fit(x_train, y_train)\n",
    "dtc_predict = dtc_random.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, dtc_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
